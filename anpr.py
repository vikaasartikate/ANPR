# -*- coding: utf-8 -*-
"""ANPR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Udr09u-iwgZMvV3MbC0ZBQ_4MY9_RZb4
"""

! pip install pytesseract

! pip install ultralytics

from google.colab import files

uploaded = files.upload()

from google.colab import drive
drive.mount('/content/drive')

folder_path = "/content/drive/My Drive/dataset"

!apt-get update
!apt-get install -y tesseract-ocr

from ultralytics import YOLO

# Define dataset path (change accordingly)
dataset_path = "/content/drive/My Drive/data.yaml"

# Load YOLOv8 model
model = YOLO("yolov8n.yaml")  # Use "yolov8n.pt" if training from pre-trained weights

# Train the model
model.train(data=dataset_path, epochs=50, batch=16, imgsz=640)

best_model_path = "/content/runs/detect/train2/weights/best.pt"
from google.colab import files

files.download(best_model_path)

!ls -lt $(find /content -name "*.pt") | head -n 1

import ultralytics
from ultralytics import YOLO
import cv2
from PIL import Image
from IPython.display import Video
import matplotlib.pyplot as plt
from IPython.display import display
import torch
import cv2
import torch
from ultralytics import YOLO
import pytesseract
ultralytics.checks()


model = YOLO(".pt")

pytesseract.pytesseract.tesseract_cmd = "/usr/bin/tesseract"


from IPython.display import display, clear_output

video_path = "/content/anpr.mp4"  # Use raw string (r"") to avoid path issues
cap = cv2.VideoCapture(video_path)

frame_count = 0  # Counter for processed frames

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("End of video or error reading frame.")
        break  # Stop if video ends

    frame_count += 10000000
    print(f"Processing Frame {frame_count}...")

    # Run YOLOv8 detection
    results = model(frame)

    for result in results:
        boxes = result.boxes.xyxy.cpu().numpy() if result.boxes is not None else []

        for box in boxes:
            x1, y1, x2, y2 = map(int, box)

            # Ensure coordinates are within bounds
            if x1 < 0 or y1 < 0 or x2 > frame.shape[1] or y2 > frame.shape[0]:
                continue

            # Crop the detected plate region
            plate_roi = frame[y1:y2, x1:x2]

            # Convert to grayscale and apply OCR
            gray_plate = cv2.cvtColor(plate_roi, cv2.COLOR_BGR2GRAY)
            number_plate_text = pytesseract.image_to_string(gray_plate, config='--psm 7')

            # Print extracted number plate
            if number_plate_text.strip():
                print(f"Detected Number Plate: {number_plate_text.strip()}")

            # Draw bounding box and label
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, number_plate_text.strip(), (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Convert frame to RGB for display
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Display frame inside Jupyter Notebook
    clear_output(wait=True)
    plt.figure(figsize=(10, 6))
    plt.imshow(frame_rgb)
    plt.axis("off")
    plt.show()

cap.release()
print("Video processing complete.")

import ultralytics
from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt
from IPython.display import display, clear_output
import pytesseract

# Check environment
ultralytics.checks()

# Load YOLOv8 model
model = YOLO("yolov8n.pt")

# Set Tesseract OCR path
pytesseract.pytesseract.tesseract_cmd = "/usr/bin/tesseract"

# Video path
video_path = "/content/anpr.mp4"
cap = cv2.VideoCapture(video_path)

# Define frame skipping strategy
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
frame_skip = max(total_frames // 10, 1)  # Skip to pick 10 frames only

frame_count = 0
processed_frames = 0  # Counter to track 10 frames

while cap.isOpened() and processed_frames < 30:
    ret, frame = cap.read()
    if not ret:
        print("End of video or error reading frame.")
        break  # Stop if video ends

    # Skip frames
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_count)
    frame_count += frame_skip  # Move to next frame

    print(f"Processing Frame {frame_count}...")

    # Run YOLOv8 detection
    results = model(frame)

    for result in results:
        boxes = result.boxes.xyxy.cpu().numpy() if result.boxes is not None else []

        for box in boxes:
            x1, y1, x2, y2 = map(int, box)

            # Ensure coordinates are within bounds
            if x1 < 0 or y1 < 0 or x2 > frame.shape[1] or y2 > frame.shape[0]:
                continue

            # Crop detected plate region
            plate_roi = frame[y1:y2, x1:x2]

            # Convert to grayscale and apply OCR
            gray_plate = cv2.cvtColor(plate_roi, cv2.COLOR_BGR2GRAY)
            number_plate_text = pytesseract.image_to_string(gray_plate, config='--psm 7')

            # Print extracted number plate
            if number_plate_text.strip():
                print(f"Detected Number Plate: {number_plate_text.strip()}")

            # Draw bounding box and label
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, number_plate_text.strip(), (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Convert frame to RGB for display
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Display frame inside Jupyter Notebook
    clear_output(wait=True)
    plt.figure(figsize=(10, 6))
    plt.imshow(frame_rgb)
    plt.axis("off")
    plt.show()

    processed_frames += 1  # Increment processed frames count

cap.release()
print("✅ Video processing complete. Only 30 frames were processed.")

model = YOLO("yolov8n.pt")

from google.colab import files

uploaded = files.upload()  # This will prompt a file upload

from google.colab import drive
drive.mount('/content/drive')

pytesseract.pytesseract.tesseract_cmd = "/usr/bin/tesseract"

import ultralytics
from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt
from IPython.display import display, clear_output
import pytesseract

# Check environment
ultralytics.checks()

# Load both YOLO models
vehicle_model = YOLO("yolov8n.pt")  # Detect vehicles
plate_model = YOLO("/content/license_plate_detector.pt")  # Detect number plates

# Set Tesseract OCR path
pytesseract.pytesseract.tesseract_cmd = "/usr/bin/tesseract"

# Video path
video_path = "/content/anpr_2.mp4"
cap = cv2.VideoCapture(video_path)

# Define frame skipping strategy
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
frame_skip = max(total_frames // 30, 1)  # Skip frames to process 30 frames only

frame_count = 0
processed_frames = 0  # Counter for processed frames

while cap.isOpened() and processed_frames < 30:
    ret, frame = cap.read()
    if not ret:
        print("End of video or error reading frame.")
        break  # Stop if video ends

    # Skip frames
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_count)
    frame_count += frame_skip  # Move to next frame

    print(f"Processing Frame {frame_count}...")

    # Step 1: Detect Vehicles
    vehicle_results = vehicle_model(frame)
    vehicle_boxes = vehicle_results[0].boxes.xyxy.cpu().numpy() if vehicle_results[0].boxes is not None else []

    for x1, y1, x2, y2 in vehicle_boxes:
        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])

        # Crop vehicle region
        vehicle_roi = frame[y1:y2, x1:x2]

        # Step 2: Detect Number Plates inside the vehicle region
        plate_results = plate_model(vehicle_roi)
        plate_boxes = plate_results[0].boxes.xyxy.cpu().numpy() if plate_results[0].boxes is not None else []

        for px1, py1, px2, py2 in plate_boxes:
            px1, py1, px2, py2 = map(int, [px1, py1, px2, py2])

            # Convert plate box coordinates to original frame
            plate_x1 = x1 + px1
            plate_y1 = y1 + py1
            plate_x2 = x1 + px2
            plate_y2 = y1 + py2

            # Crop detected plate
            plate_roi = frame[plate_y1:plate_y2, plate_x1:plate_x2]

            # Convert to grayscale for OCR
            gray_plate = cv2.cvtColor(plate_roi, cv2.COLOR_BGR2GRAY)

            # Extract number plate text
            number_plate_text = pytesseract.image_to_string(gray_plate, config='--psm 7').strip()
            print(f"Detected Number Plate: {number_plate_text}")

            # Draw number plate box
            cv2.rectangle(frame, (plate_x1, plate_y1), (plate_x2, plate_y2), (0, 255, 0), 2)
            cv2.putText(frame, number_plate_text, (plate_x1, plate_y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    # Convert frame to RGB for display
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Display frame
    clear_output(wait=True)
    plt.figure(figsize=(10, 6))
    plt.imshow(frame_rgb)
    plt.axis("off")
    plt.show()

    processed_frames += 1  # Increment processed frames count

cap.release()
print("✅ Video processing complete. Only 30 frames were processed.")

from IPython.display import display, clear_output

video_path = "/content/anpr.mp4"  # Use raw string (r"") to avoid path issues
cap = cv2.VideoCapture(video_path)

frame_count = 0  # Counter for processed frames

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("End of video or error reading frame.")
        break  # Stop if video ends

    frame_count += 1
    print(f"Processing Frame {frame_count}...")

    # Run YOLOv8 detection
    results = model(frame)

    for result in results:
        boxes = result.boxes.xyxy.cpu().numpy() if result.boxes is not None else []

        for box in boxes:
            x1, y1, x2, y2 = map(int, box)

            # Ensure coordinates are within bounds
            if x1 < 0 or y1 < 0 or x2 > frame.shape[1] or y2 > frame.shape[0]:
                continue

            # Crop the detected plate region
            plate_roi = frame[y1:y2, x1:x2]

            # Convert to grayscale and apply OCR
            gray_plate = cv2.cvtColor(plate_roi, cv2.COLOR_BGR2GRAY)
            number_plate_text = pytesseract.image_to_string(gray_plate, config='--psm 7')

            # Print extracted number plate
            if number_plate_text.strip():
                print(f"Detected Number Plate: {number_plate_text.strip()}")

            # Draw bounding box and label
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, number_plate_text.strip(), (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Convert frame to RGB for display
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Display frame inside Jupyter Notebook
    clear_output(wait=True)
    plt.figure(figsize=(10, 6))
    plt.imshow(frame_rgb)
    plt.axis("off")
    plt.show()

cap.release()
print("Video processing complete.")